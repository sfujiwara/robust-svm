Enu-SVM が convex, nonconvex どちらをといているか調べたい
Scalabilityについてはheuristicsも入れるべき
ページ制限をきちんと見ておく

Introduction でもっと詳しくロバストSVMの流れを書く
SDP 緩和など

DCA の方が SDP 緩和よりも速いという記述がある論文が無いか探す
SDP だとメモリに入らないということを根拠にDCAの方が良いと言える?
ページ数的にきついならば regression を省く?

(汎化誤差なども含め)モデル自体の良さを主張し過ぎると、アルゴリズムを売るという軸がぶれてしまう
heuristics との比較の方が大事

decision func という言葉を削る?
h(x) = < > + b = 0

(8) は [20] を引用する

mean という言葉について言われていたので, 査読者に対しては定数倍なので平均最小化と同じと主張

fig 3 の図の線を赤青でなくドットなどに変更して、線の意味をcaptionに書く

スペース次第ではregressionを抜いてみる
(15) の式が違うという指摘: 特に問題ない
(14)から出ると説明
indicator function の notation を変える
(16)式がどうやって出てきたか: u を線型近似したと回答
fig 4 a-c 標準偏差などが必要

違いがわかるoutlier ratioを列挙したと説明する
試す ratio のパターン数が違うのがまずい
それぞれ3つくらい
ratio もできるだけ合わせたいのでそのつもりで
やってみてどうしても知見が得られない結果ならば説明を加える

table 3 captionをもっとちゃんと書く

0.xxx -> .xxx と省略しても良い

(6)のところで先行研究では0-1mipをheuristicsでといていたことを説明し直す

もう一個scalablityを見せるならば、今度は次元が大きい物で

kernelの実験は多項式カーネルで精度が良い物を探す

CVRで分解する面白さ
推定量としての解釈のしやすさ
t = 0 のときに polyhedral dca が使えるような自然な DCA (論文に書き加える)
有限収束
アルゴリズムがCVaRの近似をtightにしていく過程と見られる
途中で止めても上の損失を甘く見積もっているだけで実行可能解が得られる
tr-CVaR のupper bound を求めている
nonconvexでglobal convergence を示されているのは少ない
ramp loss と本質的に似ているが, ramp loss の s 解釈しやすい、使いやすい

t = 0 に固定したものも数値実験に加える

C-SVM は結果が悪いので載せなかったと説明すれば良さそう

ロバストSVM の論文ではこういうふうにやっていると引用する
実データでテストだけを綺麗なデータにすることはできないので、人工的に入れる必要がある
