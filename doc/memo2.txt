# Scalability に関する実験
* 基本方針は変わらず
* ER-SVM (heuristics) を図に加える
  - 計算時間が長いようであれば, 時間の上限を設けても良い
* Enu-SVM などが convex, nonconvex のどちらを解いているかも調べておく
* サンプル数が多いデータセットは現在使用している cod-rna で良いので, 次元が大きいデータセットの使用を検討
  - 優先度はやや低め
  - 次元が大きいデータセットはおそらく SMO で解いている LIBSVM が有利?


# 実データに外れ値を入れた実験
* 外れ値の割合がまちまちになっているのが気持ち悪いという指摘
  - 割合のパターン数が違う (2 個だったり 3 個だったりする) のはまずいので, そこは必ず揃える (3, 5, 10% などで 3 つくらい)
- ratio もできるだけ合わせたいのでそのつもりで
- やってみてどうしても知見が得られないような結果ならば, 違いがわかる outlier ratio を列挙したと説明する


# Performance に関する実験
* t = 0 に固定したもの (パラメータの範囲を拡張していない ER-SVM) も数値実験に加える
* 一応 C-SVM も試す (本当はスペースがぎりぎりな上に論文の趣旨から外れるので載せたくない)
  - 結果次第では C-SVM は outlier があると非常に精度が落ちるので載せなかったと説明すれば良いかも


# 論文の改稿
* ページ制限をきちんと確認し直しておく
* Caption をあまり書いていない Figure や table があったので加筆 (特に table 3)
* Introduction でもっと詳しくロバストSVMの流れを書く
  - SDP 緩和や [Suzumura et al, 2014] など実験で使っていない手法についても説明はきちんとしておく
  - できれば DCA の方が SDP 緩和よりも速いという記述がある論文が見つかると良い
  - 見つからなければ SDP だとメモリに入らないということを主張すれば, 実験で比較対象に含まれていないことを上手く正当化できる
* ページ数がぎりぎりになりそうなので regression を省く予定
  - Conclusion などで regression にも使えることに言及すれば良さそう
* モデル自体の良さを主張し過ぎると、アルゴリズムを売るという軸がぶれてしまうので気を付ける
  - heuristics との比較の方が大事
* decision func という言葉を削って h(x) = < > + b = 0 と表現する
* 式 (8) は [20] を根拠として引用する
* fig 3 の図の線を赤青でなくドットなどに変更して、線の意味をcaptionに書く
* indicator function の notation を変える (I が妥当?)
* fig 4 a-c に標準偏差などが必要
* (6) のところで先行研究では 0-1 MIP を heuristics で解いていたことを説明し直す
  - Abstract と Introduction で説明したきりだったので, 説明不足で伝わりにくかった


# 査読者への返答
* (16)式がどうやって出てきたかという質問には u を線型近似したと回答
* (15) の式が違うという指摘: 正しい式なので (14) から導かれると査読者に説明
* mean という言葉の使い方について指摘されていたので, 査読者に対しては定数倍だから平均最小化と同じと主張
* CVRで分解する面白さについて
  - 推定量としての解釈のしやすさ
  - t = 0 のときに polyhedral DCA が使えるような自然な DCA (論文にも書き加える)
  - 有限収束
  - アルゴリズムがCVaRの近似をtightにしていく過程と見られる
  - 途中で止めても上の損失を甘く見積もっているだけで実行可能解が得られる
  - tr-CVaR の upper bound を求めている
  - nonconvex で global convergence を示されているのは少ない
  - ramp loss と本質的に似ているが, ramp loss のハイパーパラメータ s 解釈しやすく使いやすい
* 人工的でない real outlier も使うべきという指摘について

# 表のスペース節約
* 0.xxx -> .xxx と省略しても良い
* データセットの次元やサイズなどは別でまとめて横幅を節約
  - 実データでテストのみから outlier を除いて綺麗なデータにすることはできないので、人工的に入れる必要があるということを説明
  - ロバストSVM の論文ではこういうふうにやっていると引用する


# Kernel を使った実験
* 1 個のデータセットで簡単に見せる程度に
* 多項式カーネルを使用する予定
  - Bounded kernel だと外れ値の効果が薄そう + パラメータの範囲拡張の意味が無くなってしまうので




レビュアーの手紙を読んで本当にその内容をやっているかチェック
* 原稿の修正
  - 実験の条件: 4:3:3 で分けたなど
  - SDP やらない理由
* 図を入れる
* 図表で nu_min の表記にミスがある
* C-SVM
  - 人工データでやるので must
  - エラーバー
* Kernel を入れた実験
  - カーネルを使った時にノンコンベックスで良い結果が出るのであればそう主張すべき
  - カーネル化したらコンベックスで十分という流れでもまあ仕方がないところ
  
* SDP の言い訳は Ramp 以上のメモリの両が必要なのでというよりも出てくる解が理論的にほぼ同等であることを言ったほうが安全そう
  - メモリサイズ的にも ramp と同じくらいということは一応言う
  - lemma  を参照
  - C-SVM が極端に悪いからということを言っていたので、その根拠を図a を使えるようにする
  - nu = 0.05 に fix した場合の表を作ってみる
  - パラメータの数が同じ方が計算時間の図が自然に見える

新たな図に合わせて図f を書き直す
図f を参照しているところで0にcaseCでも潰れるということを書き加える

* tble をパラメータをfixしたものにして一度報告する
* 決まったら原稿に反映させる
* 絵も一緒に入れる
* 文章を数値実験のところを見て書き直す
